{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply transfer learning to classify wikiart images into 25 styles\n",
    "### Import VGG16 (no top layer) and extract bottleneck features for training / validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dropout, Flatten, Dense  \n",
    "from keras import applications  \n",
    "from keras.utils.np_utils import to_categorical  \n",
    "import matplotlib.pyplot as plt  \n",
    "import math  \n",
    "import cv2  \n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# dimensions of our images (required by VGG16)  \n",
    "img_width, img_height = 224, 224  \n",
    "   \n",
    "top_model_weights_path = 'bottleneck_fc_model_25.h5'  \n",
    "train_data_dir = '/Users/lizbaldo/Desktop/wikiart-master/wikiart/train'  \n",
    "validation_data_dir = '/Users/lizbaldo/Desktop/wikiart-master/wikiart/val'  \n",
    "   \n",
    "# number of epochs to train top model  \n",
    "epochs = 50  \n",
    "# batch size used by flow_from_directory and predict_generator \n",
    "# more than 16 and my RAM goes crazy...\n",
    "batch_size = 16  \n",
    "\n",
    "model = applications.VGG16(include_top=False, weights='imagenet') \n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)  \n",
    " \n",
    "# TRAINING DATA   \n",
    "generator_train = datagen.flow_from_directory(  \n",
    "     train_data_dir,  \n",
    "     target_size=(img_width, img_height),  \n",
    "     batch_size=batch_size,  \n",
    "     class_mode=None,  \n",
    "     shuffle=False)  \n",
    "   \n",
    "nb_train_samples = len(generator_train.filenames)  \n",
    "num_classes = len(generator_train.class_indices)  \n",
    "   \n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))  \n",
    "   \n",
    "bottleneck_features_train = model.predict_generator(  \n",
    "      generator_train, predict_size_train)  \n",
    "   \n",
    "np.save('bottleneck_features_25_train.npy', bottleneck_features_train)  \n",
    "\n",
    "# VALIDATION DATA\n",
    "generator_val = datagen.flow_from_directory(  \n",
    "     validation_data_dir,  \n",
    "     target_size=(img_width, img_height),  \n",
    "     batch_size=batch_size,  \n",
    "     class_mode=None,  \n",
    "     shuffle=False)  \n",
    "   \n",
    "nb_validation_samples = len(generator_val.filenames)  \n",
    "   \n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
    "   \n",
    "bottleneck_features_validation = model.predict_generator(  \n",
    "     generator_val, predict_size_validation)  \n",
    "   \n",
    "np.save('bottleneck_features_25_validation.npy', bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA\n",
    "datagen_top = ImageDataGenerator(rescale=1./255)  \n",
    "generator_top = datagen_top.flow_from_directory(  \n",
    "         train_data_dir,  \n",
    "         target_size=(img_width, img_height),  \n",
    "         batch_size=batch_size,  \n",
    "         class_mode='categorical',  \n",
    "         shuffle=False)  \n",
    "   \n",
    "nb_train_samples = len(generator_top.filenames)  \n",
    "num_classes = len(generator_top.class_indices)  \n",
    "   \n",
    "# load the bottleneck features saved earlier  \n",
    "train_data = np.load('bottleneck_features_5_train.npy')    \n",
    "# get the class labels for the training data, in the original order  \n",
    "train_labels = generator_top.classes  \n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "# VALIDATION DATA\n",
    "generator_top = datagen_top.flow_from_directory(  \n",
    "         validation_data_dir,  \n",
    "         target_size=(img_width, img_height),  \n",
    "         batch_size=batch_size,  \n",
    "         class_mode=None,  \n",
    "         shuffle=False)  \n",
    "   \n",
    "nb_validation_samples = len(generator_top.filenames)  \n",
    "   \n",
    "validation_data = np.load('bottleneck_features_25_validation.npy')   \n",
    "validation_labels = generator_top.classes  \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, callbacks\n",
    "from visual_callbacks import ConfusionMatrixPlotter\n",
    "import time\n",
    "\n",
    "# Need one more convolutional layer -> bottleneck features not enough   \n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, 3, activation='relu', input_shape=train_data.shape[1:]))\n",
    "model.add(MaxPool2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu')) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(num_classes, activation='sigmoid')) \n",
    "\n",
    "# Took quite a lot of trial and errors to get these right...\n",
    "sgd = optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "model.compile(optimizer=sgd,  \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "\n",
    "# Great script adapted from https://github.com/chasingbob/keras-visuals\n",
    "plotter = ConfusionMatrixPlotter(X_val=validation_data, classes=generator_train.class_indices, Y_val=validation_labels)\n",
    "\n",
    "history = model.fit(train_data, train_labels,  \n",
    "          epochs=epochs,  \n",
    "          batch_size=batch_size,  \n",
    "          validation_data=(validation_data, validation_labels),callbacks=[plotter])  \n",
    "   \n",
    "model.save('my_model_25.h5')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    plt.figure(1)  \n",
    "    # summarize history for accuracy  \n",
    "    plt.plot(history.history['acc'])  \n",
    "    plt.plot(history.history['val_acc'])  \n",
    "    plt.title('model accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'test'], loc='upper left')  \n",
    "    plt.show()  \n",
    "    # summarize history for loss  \n",
    "    plt.figure(2) \n",
    "    plt.plot(history.history['loss'])  \n",
    "    plt.plot(history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'test'], loc='upper right')  \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to predict classes for new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image  import load_img,img_to_array\n",
    "from keras.models import load_model\n",
    "model = load_model('my_model_25.h5')\n",
    "\n",
    "target_size = (224, 224) #fixed size for VGG16 architecture\n",
    "\n",
    "img = '/Users/lizbaldo/Desktop/Ukiyo-e_example.jpg' # Replace with your own image\n",
    "\n",
    "# preprocess image\n",
    "image = load_img(img, target_size=target_size)  \n",
    "image = img_to_array(image)     \n",
    "image = image / 255   # important! otherwise the predictions will be '0'  \n",
    "image = np.expand_dims(image, axis=0)  \n",
    "\n",
    "# build the VGG16 network  \n",
    "model_vgg16 = applications.VGG16(include_top=False, weights='imagenet') \n",
    "# get the bottleneck prediction from the pre-trained VGG16 model  \n",
    "bottleneck_prediction = model_vgg16.predict(image)  \n",
    "class_predicted = model.predict(bottleneck_prediction)\n",
    "\n",
    "inID = class_predicted[0]  \n",
    "   \n",
    "class_dictionary = generator_top.class_indices  \n",
    "   \n",
    "inv_map = {v: k for k, v in class_dictionary.items()}  \n",
    "   \n",
    "label = inv_map[inID]  \n",
    "   \n",
    " # get the prediction label  \n",
    "print(\"Image Label: {}\".format(label))  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
